import json
import logging.config
import warnings
from os import environ, path
from typing import Dict, List, Tuple

from dotenv import load_dotenv
from fastapi.encoders import jsonable_encoder

from agr_literature_service.api.models import ResourceModel, CrossReferenceModel
# from agr_literature_service.lit_processing.data_ingest.utils.file_processing_utils import save_resource_file
from agr_literature_service.lit_processing.utils.sqlalchemy_utils import create_postgres_session,\
    sqlalchemy_load_ref_xref
from sqlalchemy.orm.exc import NoResultFound
from agr_literature_service.lit_processing.utils.generic_utils import split_identifier
from agr_literature_service.lit_processing.data_ingest.dqm_ingest.utils.dqm_processing_utils import \
    compare_authors_or_editors
from agr_literature_service.api.user import set_global_user_id
from agr_literature_service.lit_processing.utils.tmp_files_utils import init_tmp_dir
from agr_literature_service.lit_processing.data_ingest.post_resource_to_db import \
    process_resource_entry

warnings.filterwarnings("ignore", category=UserWarning, module='bs4')

load_dotenv()
init_tmp_dir()

remap_keys: Dict = {}
simple_fields: List = []
list_fields: List = []
xref_ref: Dict = {}
ref_xref_valid = {}
ref_xref_obsolete = {}
# pipenv run python sort_dqm_json_resource_updates.py

# first run  get_datatypes_cross_references.py  to generate mappings from references to xrefs and resources to xrefs
# and  generate_pubmed_nlm_resource.py  to generate pubmed_resource_json/resource_pubmed_all.json

# Attention Paulo: This is still in progress, need to test it against a newly populated database after hearing back about oddly high-numbered NLMs

# rename this to sort_dqm_json_resource_updates
# work off of sanitized_resource_json  mod + NLM files
# should it also update NLM resources ?  yes, 13.5 minutes is not long
# test time to get all resources 0000042513 - 13.5 minutes.
# keep working off of lit-4003, comparing data from 20211025 files (loaded at lit-4005)


log_file_path = path.join(path.dirname(path.abspath(__file__)), '../../../../logging.conf')
logging.config.fileConfig(log_file_path)
logger = logging.getLogger('literature logger')

batch_size_for_commit = 250


def load_sanitized_resource(datatype, filename):
    """
    Load sanitized resource data generated by parse_dqm_json_resource.py

    :param datatype:
    :return:
    """
    sanitized_resources = dict()
    try:
        with open(filename, 'r') as f:
            whole_dict = json.load(f)
            if 'data' in whole_dict:
                sanitized_resources = whole_dict['data']
    except IOError as e:
        logger.warning(f"Unable to read file {filename}. Error {e}")
    return sanitized_resources


def update_sanitized_resources(db_session, datatype, filename):
    """
    datatype is a MOD or NLM.  sort against resource_curie_to_xref from
    get_datatypes_cross_references.py query of database.  sort into resources to
    update, or to create: saving those to sanitized_resource_json_updates/ to post
    to db with post_resource_to_api.py

    :param datatype:
    :return:
    """
    scriptNm = path.basename(__file__).replace(".py", "")
    set_global_user_id(db_session, scriptNm)

    logger.info("update_sanitized_resources for %s", datatype)

    xref_ref, ref_xref_valid, ref_xref_obsolete = sqlalchemy_load_ref_xref('resource')

    sanitized_resources = load_sanitized_resource(datatype, filename)
    resources_to_update = dict()

    counter = 0
    new = 0
    updated = 0
    # make this True for live changes
    # live_changes = False
    live_changes = True
    for resource_dict in sanitized_resources:
        counter = counter + 1
        # if counter > 2:
        #     break
        found = False
        primary_id = resource_dict['primaryId']
        prefix, identifier, separator = split_identifier(primary_id)
        logger.info("primary_id %s pubmed %s", primary_id, resource_dict)
        if prefix in xref_ref:
            if identifier in xref_ref[prefix]:
                agr = xref_ref[prefix][identifier]
                if agr in resources_to_update:
                    logger.info("ERROR agr %s has multiple values to update %s %s", agr, primary_id, resources_to_update[agr]['primaryId'])
                else:
                    resources_to_update[agr] = resource_dict
                logger.info("update primary_id %s db %s", primary_id, agr)
                found = True
                updated += 1
        if not found:
            # logger.info("create primary_id %s", primary_id)
            # resources_to_create[primary_id] = resource_dict
            # load directly
            process_okay, message = process_resource_entry(db_session, resource_dict, xref_ref)
            if process_okay:
                if message:
                    logger.info(message)
                else:
                    logger.error(message)
            new += 1
    logger.info(f"{counter} resources seen. {new} new, {updated} updated.")

    update_resources(db_session, live_changes, resources_to_update)

    db_session.close()


def update_resource(db_session, dqm_entry, db_entry) -> None:
    global simple_fields
    global list_fields
    global remap_keys
    if not simple_fields:
        simple_fields = ['title', 'isoAbbreviation', 'medlineAbbreviation', 'printISSN',
                         'onlineISSN', 'publisher', 'pages']
    if not list_fields:
        list_fields = ['abbreviationSynonyms', 'titleSynonyms', 'volumes']
    if not remap_keys:
        remap_keys['isoAbbreviation'] = 'iso_abbreviation'
        remap_keys['medlineAbbreviation'] = 'medline_abbreviation'
        remap_keys['printISSN'] = 'print_issn'
        remap_keys['onlineISSN'] = 'online_issn'
        remap_keys['abbreviationSynonyms'] = 'abbreviation_synonyms'
        remap_keys['titleSynonyms'] = 'title_synonyms'
        remap_keys['crossReferences'] = 'cross_references'
        remap_keys['editorsOrAuthors'] = 'editors'

    agr = db_entry['curie']
    update_json = dict()
    for field_camel in simple_fields:
        field_snake = camel_to_snake(field_camel, remap_keys)
        dqm_value = None
        db_value = None
        if field_camel in dqm_entry:
            dqm_value = dqm_entry[field_camel]
        if field_snake in db_entry:
            db_value = db_entry[field_snake]
        if dqm_value != db_value:
            logger.info(f"patch {agr} field {field_snake} from db {db_value} to pm {dqm_value}")
            update_json[field_snake] = dqm_value
    for field_camel in list_fields:
        list_changed = compare_list(db_entry, dqm_entry, field_camel, remap_keys)
        if list_changed[0]:
            logger.info("patch %s field %s from db %s to dqm %s", agr, list_changed[3], list_changed[2], list_changed[1])
            update_json[list_changed[3]] = list_changed[1]
    if update_json:
        try:
            db_session.query(ResourceModel).filter_by(curie=agr).update(update_json)
            db_session.commit()
            logger.info("The resource row for curie = " + agr + " has been updated.")
        except Exception as e:
            logger.error("An error occurred when updating resource row for curie = " + agr + " " + str(e))
    return


def process_update_resource(db_session, dqm_entry, agr) -> Tuple:
    global xref_ref, ref_xref_valid, ref_xref_obsolete
    if not xref_ref:
        xref_ref, ref_xref_valid, ref_xref_obsolete = sqlalchemy_load_ref_xref('resource')
    try:
        db_entry = db_session.query(ResourceModel).filter(ResourceModel.curie == agr).one()
    except NoResultFound:
        return False, f"Unable to find unique resource with curie {agr}."
    db_entry = jsonable_encoder(db_entry)
    update_resource(db_session, dqm_entry, db_entry)
    if 'crossReferences' in dqm_entry:
        compare_xref(db_session, agr, db_entry['resource_id'], dqm_entry,
                     xref_ref, ref_xref_valid, ref_xref_obsolete)
    editors_changed = compare_authors_or_editors(db_entry, dqm_entry, 'editors')
    # editor API needs updates.  reference_curie required to post reference authors but for some reason resource_curie not allowed here, cannot connect new editor to resource if resource_curie is not passed in
    if editors_changed[0]:
        pass
    #    # live_changes = True
    #    # e.g. FB:FBmultipub_7448
    #    for patch_data in editors_changed[1]:
    #        patch_dict = patch_data['patch_dict']
    #        # patch_dict['resource_curie'] = agr   # reference_curie required to patch reference authors but for some reason not allowed here
    #        logger.info("patch %s editor_id %s patch_dict %s", agr, patch_data['editor_id'], patch_dict)
    #        editor_patch_url = 'http://localhost:' + api_port + '/editor/' + str(patch_data['editor_id'])
    #        headers = generic_api_patch(live_changes, editor_patch_url, headers, patch_dict, str(patch_data['editor_id']), None, None)
    #    for create_dict in editors_changed[2]:
    #        create_dict['resource_curie'] = agr   # reference_curie required to post reference authors but for some reason not allowed here
    #        logger.info("add to %s create_dict %s", agr, create_dict)
    #        editor_post_url = 'http://localhost:' + api_port + '/editor/'
    #        headers = generic_api_post(live_changes, editor_post_url, headers, create_dict, agr, None, None)
    return True, "Okay"


def update_resources(db_session, live_changes, resources_to_update):
    """
    Get the resource from the database, compare to the new resource data.
    Patch simple and list fields.  Add new cross_references and track other
    cases until curators tell us what reports they want.
    This takes 11 minutes to query 34284 resources one by one through the API

    :param live_changes:
    :param resources_to_update:
    :return:
    """

    for agr in resources_to_update:
        process_update_resource(db_session, resources_to_update[agr], agr)


def camel_to_snake(field_camel, remap_keys):
    """

    :param field_camel:
    :param remap_keys:
    :return:
    """

    field_snake = field_camel
    if field_camel in remap_keys:
        field_snake = remap_keys[field_camel]
    return field_snake


def compare_xref(db_session, agr, resource_id, dqm_entry, xref_ref, ref_xref_valid, ref_xref_obsolete):
    """
    We're running dqm resource updates mod by mod instead of aggregating all their data into
    one entry and comparing that to the database.  Since we cannot track which mod submission
    an xref went into the database with, we cannot tell which ones should be removed.
    For example, if for a given resource FB sends an ISSN and ZFIN sends an ISBN, when running
    the ZFIN update it will see that the database has an ISSN that ZFIN doesn't have, so it
    will create notification about things that ZFIN doesn't necessarily care about.
    For that reason we're only doing of xrefs, and removals will have to be done at ABC
    through the UI.

    :param agr:
    :param resource_id
    :param dqm_entry:
    :param xref_ref:
    :param ref_xref_valid:
    :param ref_xref_obsolete:
    :param headers:
    :param live_changes:
    :return:
    """

    # api_port = environ.get('API_PORT')
    # url = 'http://' + api_server + ':' + api_port + '/cross_reference/'

    for xref in dqm_entry['crossReferences']:
        curie = xref['id']
        prefix, identifier, separator = split_identifier(curie)
        agr_db_from_xref = ''
        if prefix in xref_ref:
            if identifier in xref_ref[prefix]:
                agr_db_from_xref = xref_ref[prefix][identifier]
        # depending on what curators want for reports, these commented out logger.info should go into reports
        if agr_db_from_xref == agr:
            pass
            # logger.info("GOOD1: cross_reference %s good in %s", curie, agr)
        elif agr_db_from_xref != '':
            pass
            # these are probably useful to curators, have conflicts of xref mapping to
            # different agr resources before and after
            # logger.info("REMAP: cross_reference %s already exists in %s", curie, agr_db_from_xref)
        else:
            dqm_xref_obsolete_found = False
            dqm_xref_valid_found = False    # noqa: F841
            if agr in ref_xref_obsolete:
                if prefix in ref_xref_obsolete[agr]:
                    if identifier.lower() in ref_xref_obsolete[agr][prefix]:
                        dqm_xref_obsolete_found = True    # noqa: F841
                        # logger.info("OBSOLETE: cross_reference %s obsolete in %s", curie, agr)
            elif agr in ref_xref_valid:
                if prefix in ref_xref_valid[agr]:
                    if identifier.lower() == ref_xref_valid[agr][prefix].lower():
                        # this should never happen, equivalent to GOOD1 unless something went wrong somewhere
                        pass
                        # logger.info("GOOD2: cross_reference %s good in %s", curie, agr)
                    else:
                        pass
                        # logger.info("RENAMED: cross_reference %s prefix %s was %s new dqm value %s in %s", curie, prefix, ref_xref_valid[agr][prefix], identifier, agr)
                else:
                    try:
                        logger.info("CREATE: add cross_reference %s to %s", curie, agr)
                        x = CrossReferenceModel(curie=curie,
                                                resource_id=resource_id,
                                                pages=xref.get('pages', []))
                        db_session.add(x)
                        logger.info("The cross_reference row for curie = " + curie + " and resource_curie = " + agr + " has been added into database.")
                    except Exception as e:
                        logger.info("An error occurred when adding cross_reference row for curie = " + curie + " and resource_curie = " + agr + " " + str(e))


def compare_list(db_entry, dqm_entry, field_camel, remap_keys):
    """
    compare case-insensitive if two lists contain the same values from db and dqm dicts

    :param db_entry:
    :param dqm_entry:
    :param field_camel:
    :param remap_keys:
    :return:
    """

    field_snake = camel_to_snake(field_camel, remap_keys)
    db_values = []
    dqm_values = []
    if field_snake in db_entry:
        if db_entry[field_snake] is not None:
            db_values = db_entry[field_snake]
    lower_db_values = [i.lower() for i in db_values]
    if field_camel in dqm_entry:
        if dqm_entry[field_camel] is not None:
            dqm_values = dqm_entry[field_camel]
    lower_dqm_values = [i.lower() for i in dqm_values]
    if set(lower_db_values) == set(lower_dqm_values):
        return False, None, None
    else:
        return True, dqm_values, db_values, field_snake


if __name__ == "__main__":
    """
    call main start function
    """

    logger.info("starting sort_dqm_json_resource_updates.py")
    db_session = create_postgres_session(False)
    # mods and special NLM
    mods = ['RGD', 'MGI', 'SGD', 'FB', 'ZFIN', 'WB', 'NLM']
    for mod in mods:
        base_path = environ.get('XML_PATH', 'undefined')
        filename = base_path + 'sanitized_resource_json/RESOURCE_' + mod + '.json'
        update_sanitized_resources(db_session, mod, filename)

    logger.info("ending sort_dqm_json_resource_updates.py")
