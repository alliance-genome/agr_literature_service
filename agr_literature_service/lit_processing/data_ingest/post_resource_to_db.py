import argparse
import json
import logging.config
import sys
from os import environ

from dotenv import load_dotenv

from agr_literature_service.lit_processing.utils.sqlalchemy_utils import create_postgres_session, \
    sqlalchemy_load_ref_xref
from agr_literature_service.api.models import ResourceModel, CrossReferenceModel, EditorModel
from agr_literature_service.api.crud.resource_crud import create_next_curie
from agr_literature_service.lit_processing.utils.generic_utils import split_identifier
from agr_literature_service.lit_processing.utils.tmp_files_utils import init_tmp_dir

load_dotenv()
init_tmp_dir()

# pipenv run python3 post_resource_to_api.py > log_post_resource_to_api

# resource_fields = ['primaryId', 'nlm', 'title', 'isoAbbreviation', 'medlineAbbreviation', 'printISSN', 'onlineISSN']
# resource_fields_from_pubmed = ['title', 'isoAbbreviation', 'medlineAbbreviation', 'printISSN', 'onlineISSN']

resource_fields_not_in_pubmed = ['titleSynonyms', 'abbreviationSynonyms', 'isoAbbreviation',
                                 'copyrightDate', 'publisher', 'editorsOrAuthors',
                                 'volumes', 'pages', 'abstractOrSummary']

# keys that exist in data
# 2021-05-24 23:06:27,844 - literature logger - INFO - key publisher
# 2021-05-24 23:06:27,844 - literature logger - INFO - key isoAbbreviation
# 2021-05-24 23:06:27,844 - literature logger - INFO - key title
# 2021-05-24 23:06:27,844 - literature logger - INFO - key primaryId
# 2021-05-24 23:06:27,844 - literature logger - INFO - key medlineAbbreviation
# 2021-05-24 23:06:27,844 - literature logger - INFO - key onlineISSN
# 2021-05-24 23:06:27,844 - literature logger - INFO - key abbreviationSynonyms
# 2021-05-24 23:06:27,844 - literature logger - INFO - key volumes
# 2021-05-24 23:06:27,844 - literature logger - INFO - key crossReferences
# 2021-05-24 23:06:27,844 - literature logger - INFO - key editorsOrAuthors
# 2021-05-24 23:06:27,844 - literature logger - INFO - key nlm
# 2021-05-24 23:06:27,845 - literature logger - INFO - key pages
# 2021-05-24 23:06:27,845 - literature logger - INFO - key printISSN


logging.basicConfig(level=logging.INFO,
                    stream=sys.stdout,
                    format= '%(asctime)s - %(levelname)s - {%(module)s %(funcName)s:%(lineno)d} - %(message)s',    # noqa E251
                    datefmt='%Y-%m-%d %H:%M:%S')
logger = logging.getLogger(__name__)

base_path = environ.get('XML_PATH', "")


def post_resources(input_path, input_mod, base_input_dir=base_path):      # noqa: C901
    """

    :param input_path:
    :return:
    """

    json_storage_path = base_input_dir + input_path + '/'
    filesets = ['NLM', 'FB', 'ZFIN']
    if input_mod in filesets:
        filesets = [input_mod]
    keys_to_remove = {'nlm', 'primaryId'}
    remap_keys = dict()
    remap_keys['isoAbbreviation'] = 'iso_abbreviation'
    remap_keys['medlineAbbreviation'] = 'medline_abbreviation'
    remap_keys['abbreviationSynonyms'] = 'abbreviation_synonyms'
    remap_keys['crossReferences'] = 'cross_references'
    remap_keys['editorsOrAuthors'] = 'editors'
    remap_keys['printISSN'] = 'print_issn'
    remap_keys['onlineISSN'] = 'online_issn'
    editor_keys_to_remove = {'referenceId'}
    remap_editor_keys = dict()
    remap_editor_keys['authorRank'] = 'order'
    remap_editor_keys['firstName'] = 'first_name'
    remap_editor_keys['lastName'] = 'last_name'
    cross_references_keys_to_remove = dict()
    remap_cross_references_keys = dict()
    remap_cross_references_keys['id'] = 'curie'
    keys_found = set()

    resource_primary_id_to_curie_file = base_path + 'resource_primary_id_to_curie'
    errors_in_posting_resource_file = base_path + 'errors_in_posting_resource'

    # generate_cross_references_file('resource')
    # this updates from resources in the database, and takes 4 seconds.
    # if updating this script, comment it out after running it once
    # xref_ref, ref_xref_valid, ref_xref_obsolete = load_ref_xref_api_flatfile('resource')
    xref_ref, ref_xref_valid, ref_xref_obsolete = sqlalchemy_load_ref_xref('resource')

    # populating already_processed_primary_id from file generated by this script
    # to log created agr resource curies and identifiers, obsoleted by xref_ref
    # already_processed_primary_id = set()
    # if path.isfile(resource_primary_id_to_curie_file):
    #     with open(resource_primary_id_to_curie_file, 'r') as read_fh:
    #         for line in read_fh:
    #             line_data = line.split("\t")
    #             if line_data[0]:
    #                 already_processed_primary_id.add(line_data[0].rstrip())

    db_session = create_postgres_session(False)

    with open(resource_primary_id_to_curie_file, 'a') as mapping_fh, open(errors_in_posting_resource_file, 'a') as error_fh:

        for fileset in filesets:
            logger.info("processing %s", fileset)
            # if fileset != 'NLM':
            #     continue

            filename = json_storage_path + 'RESOURCE_' + fileset + '.json'
            f = open(filename)
            resource_data = json.load(f)
            for entry in resource_data['data']:
                primary_id = entry['primaryId']
                prefix, identifier, separator = split_identifier(primary_id)
                if prefix in xref_ref:
                    if identifier in xref_ref[prefix]:
                        logger.info("%s\talready in", primary_id)
                        continue
                # if primary_id in already_processed_primary_id:
                #     # logger.info("%s\talready in", primary_id)
                #     continue
                # if primary_id != 'NLM:8404639':
                #     continue

                # counter += 1
                # if counter > 1:
                #     break

                # to debug json from data file before changes
                # json_object = json.dumps(entry, indent=4)
                # print("before " + json_object)

                new_entry = dict()

                for key in entry:
                    keys_found.add(key)
                    # logger.info("key found\t%s\t%s", key, entry[key])
                    if key in remap_keys:
                        # logger.info("remap\t%s\t%s", key, remap_keys[key])
                        # this renames a key, but it can be accessed again in the
                        # for key loop, so sometimes a key is visited twice while
                        # another is skipped, so have to create a new dict
                        # to populate instead
                        # entry[remap_keys[key]] = entry.pop(key)
                        new_entry[remap_keys[key]] = entry[key]
                    elif key not in keys_to_remove:
                        new_entry[key] = entry[key]
                try:
                    resource_id = None
                    curie = create_next_curie()
                    cross_references = new_entry.get('cross_references', [])
                    editors = new_entry.get('editors', [])
                    if "cross_references" in new_entry:
                        del new_entry["cross_references"]
                    if "editors" in new_entry:
                        del new_entry["editors"]
                    new_entry['curie'] = curie
                    x = ResourceModel(**new_entry)
                    db_session.add(x)
                    db_session.flush()
                    db_session.refresh(x)
                    resource_id = x.resource_id
                    logger.info("Adding resource into database for '" + new_entry['iso_abbreviation'] + "'")
                    mapping_fh.write("%s\t%s\n" % (primary_id, curie))

                    for xref in cross_references:
                        new_xref = dict()
                        for subkey in xref:
                            if subkey in remap_cross_references_keys:
                                new_xref[remap_cross_references_keys[subkey]] = xref[subkey]
                            elif subkey not in cross_references_keys_to_remove:
                                new_xref[subkey] = xref[subkey]
                        new_xref['resource_id'] = resource_id
                        if db_session.query(CrossReferenceModel).filter_by(curie=new_xref['curie']).first():
                            logger.info("CrossReference with curie = " + new_xref['curie'] + " already exists")
                            db_session.rollback()
                            break
                        cr = CrossReferenceModel(**new_xref)
                        db_session.add(cr)
                        logger.info("Adding resource info into cross_reference table for " + new_xref['curie'])

                    for editor in editors:
                        new_editor = dict()
                        for subkey in editor:
                            if subkey in remap_editor_keys:
                                new_editor[remap_editor_keys[subkey]] = editor[subkey]
                            elif subkey not in editor_keys_to_remove:
                                new_editor[subkey] = editor[subkey]
                        if new_editor.get('orcid') and new_editor['orcid']:
                            cross_reference_obj = db_session.query(
                                CrossReferenceModel).filter_by(
                                    curie=new_editor['orcid']).first()
                            if not cross_reference_obj:
                                cross_reference_obj = CrossReferenceModel(curie=new_editor['orcid'])
                                db_session.add(cross_reference_obj)
                        new_editor['resource_id'] = resource_id
                        editor_obj = EditorModel(**new_editor)
                        db_session.add(editor_obj)
                    db_session.commit()
                except Exception as e:
                    logger.info("An error occurred when adding resource into database for '" + new_entry['iso_abbreviation'] + "'. " + str(e))
                    error_fh.write("An error occurred when adding resource into database for '" + new_entry['iso_abbreviation'] + "'. " + str(e) + "\n")
                    db_session.rollback()

        mapping_fh.close
        error_fh.close
        db_session.close()


if __name__ == "__main__":
    """
    call main start function
    """

    parser = argparse.ArgumentParser()
    parser.add_argument('-f', '--file', action='store', help='take input from RESOURCE files in full path')

    args = vars(parser.parse_args())

    logger.info("starting post_resource_to_api.py")

    if args['file']:
        post_resources(args['file'], 'all')

    else:
        logger.info("No flag passed in.  Use -h for help.")

    logger.info("ending post_resource_to_api.py")

# pipenv run python3 post_resource_to_api.py
